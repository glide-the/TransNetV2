{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91d757-a040-4aa0-9105-fa74e3c6c220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting tensorflow-gpu==2.10.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6e/27/150049eed18027b8ac451e3552a036806d4afe2f49304d397d37933ef77e/tensorflow_gpu-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.66.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (3.11.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (24.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (0.37.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.10.0) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.2.2)\n",
      "Installing collected packages: tensorflow-gpu\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.10.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af2c113-6513-44c8-9619-46a7ad27d5cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: ffmpeg-python in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: pillow in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (10.4.0)\n",
      "Requirement already satisfied: future in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from ffmpeg-python) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install ffmpeg-python pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003e2341-daec-4d21-8d10-f16fced1db11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting numpy<2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/4b/d7/ecf66c1cd12dc28b4040b15ab4d17b773b87fa9d29ca16125de01adb36cd/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3773c993-bbdf-4409-9c60-6109df0baa55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- --------------\n",
      "absl-py                      2.1.0\n",
      "anyio                        4.4.0\n",
      "argon2-cffi                  23.1.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.3.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.4\n",
      "attrs                        24.2.0\n",
      "babel                        2.16.0\n",
      "beautifulsoup4               4.12.3\n",
      "bleach                       6.1.0\n",
      "cachetools                   5.5.0\n",
      "certifi                      2024.8.30\n",
      "cffi                         1.17.1\n",
      "charset-normalizer           3.3.2\n",
      "comm                         0.2.2\n",
      "debugpy                      1.8.5\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "exceptiongroup               1.2.2\n",
      "executing                    2.1.0\n",
      "fastjsonschema               2.20.0\n",
      "ffmpeg-python                0.2.0\n",
      "flatbuffers                  24.3.25\n",
      "fqdn                         1.5.1\n",
      "future                       1.0.0\n",
      "gast                         0.4.0\n",
      "google-auth                  2.34.0\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.66.1\n",
      "h11                          0.14.0\n",
      "h5py                         3.11.0\n",
      "httpcore                     1.0.5\n",
      "httpx                        0.27.2\n",
      "idna                         3.8\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.27.0\n",
      "isoduration                  20.11.0\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.4\n",
      "json5                        0.9.25\n",
      "jsonpointer                  3.0.0\n",
      "jsonschema                   4.23.0\n",
      "jsonschema-specifications    2023.12.1\n",
      "jupyter_client               8.6.2\n",
      "jupyter_core                 5.7.2\n",
      "jupyter-events               0.10.0\n",
      "jupyter-lsp                  2.2.5\n",
      "jupyter_server               2.14.2\n",
      "jupyter_server_terminals     0.5.3\n",
      "jupyterlab                   4.2.5\n",
      "jupyterlab_pygments          0.3.0\n",
      "jupyterlab_server            2.27.3\n",
      "keras                        2.10.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.7\n",
      "MarkupSafe                   2.1.5\n",
      "matplotlib-inline            0.1.7\n",
      "mistune                      3.0.2\n",
      "nbclient                     0.10.0\n",
      "nbconvert                    7.16.4\n",
      "nbformat                     5.10.4\n",
      "nest-asyncio                 1.6.0\n",
      "notebook_shim                0.2.4\n",
      "numpy                        1.26.4\n",
      "oauthlib                     3.2.2\n",
      "opt-einsum                   3.3.0\n",
      "overrides                    7.7.0\n",
      "packaging                    24.1\n",
      "pandocfilters                1.5.1\n",
      "parso                        0.8.4\n",
      "pexpect                      4.9.0\n",
      "pillow                       10.4.0\n",
      "pip                          24.2\n",
      "platformdirs                 4.2.2\n",
      "prometheus_client            0.20.0\n",
      "prompt_toolkit               3.0.47\n",
      "protobuf                     3.19.6\n",
      "psutil                       6.0.0\n",
      "ptyprocess                   0.7.0\n",
      "pure_eval                    0.2.3\n",
      "pyasn1                       0.6.0\n",
      "pyasn1_modules               0.4.0\n",
      "pycparser                    2.22\n",
      "Pygments                     2.18.0\n",
      "python-dateutil              2.9.0.post0\n",
      "python-json-logger           2.0.7\n",
      "PyYAML                       6.0.2\n",
      "pyzmq                        26.2.0\n",
      "referencing                  0.35.1\n",
      "requests                     2.32.3\n",
      "requests-oauthlib            2.0.0\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rpds-py                      0.20.0\n",
      "rsa                          4.9\n",
      "Send2Trash                   1.8.3\n",
      "setuptools                   72.1.0\n",
      "six                          1.16.0\n",
      "sniffio                      1.3.1\n",
      "soupsieve                    2.6\n",
      "stack-data                   0.6.3\n",
      "tensorboard                  2.10.1\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.10.0\n",
      "tensorflow-estimator         2.10.0\n",
      "tensorflow-io-gcs-filesystem 0.37.1\n",
      "termcolor                    2.4.0\n",
      "terminado                    0.18.1\n",
      "tinycss2                     1.3.0\n",
      "tomli                        2.0.1\n",
      "tornado                      6.4.1\n",
      "traitlets                    5.14.3\n",
      "types-python-dateutil        2.9.0.20240906\n",
      "typing_extensions            4.12.2\n",
      "uri-template                 1.3.0\n",
      "urllib3                      2.2.2\n",
      "wcwidth                      0.2.13\n",
      "webcolors                    24.8.0\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.8.0\n",
      "Werkzeug                     3.0.4\n",
      "wheel                        0.43.0\n",
      "wrapt                        1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d827efe-a75e-479c-a797-89ba5d9a2844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 18:01:30.032292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-07 18:01:30.150967: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-07 18:01:30.156358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-09-07 18:01:30.156369: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-09-07 18:01:30.181039: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-07 18:01:34.721096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-07 18:01:34.721987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-07 18:01:34.722011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74290fb3-9d2c-4a74-a973-9f6c7734b2c2",
   "metadata": {},
   "source": [
    "### 移动视频符合要求目录\n",
    "把 video_org下面的mp4文件，移动到 video_org_test下面 一个视频一个文件夹，命名使用test_{index}/test_{index}.mp4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b93fe76-e34b-4742-bb59-5a2f99bb7a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "搞定，所有视频都整好了！💪\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 源文件夹和目标文件夹路径\n",
    "source_dir = '/mnt/ceph/develop/jiawei/lora_dataset/video_org'\n",
    "dest_dir = '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站/'\n",
    "\n",
    "# 获取所有的 mp4 文件\n",
    "mp4_files = [f for f in os.listdir(source_dir) if f.endswith('.mp4')]\n",
    "\n",
    "# 遍历每个文件并创建目标文件夹\n",
    "for index, file_name in enumerate(mp4_files, 1):\n",
    "    # 创建新的文件夹名称\n",
    "    new_folder_name = f'test_{index}'\n",
    "    new_folder_path = os.path.join(dest_dir, new_folder_name)\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    \n",
    "    # 移动并重命名文件\n",
    "    src_file_path = os.path.join(source_dir, file_name)\n",
    "    dest_file_path = os.path.join(new_folder_path, f'test_{index}.mp4')\n",
    "    shutil.move(src_file_path, dest_file_path)\n",
    "\n",
    "print(\"搞定，所有视频都整好了！💪\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1f32a18-844f-4c74-948f-d90065ef1533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_files:['/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1/test1.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2/test2.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1/test_1.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_10/test_10.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_11/test_11.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12/test_12.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_13/test_13.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_14/test_14.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_15/test_15.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_16/test_16.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_17/test_17.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_18/test_18.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19/test_19.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2/test_2.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_20/test_20.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21/test_21.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_22/test_22.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23/test_23.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24/test_24.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25/test_25.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26/test_26.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27/test_27.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28/test_28.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_29/test_29.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_3/test_3.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_4/test_4.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_5/test_5.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_6/test_6.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7/test_7.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8/test_8.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_9/test_9.mp4']\n",
      "[TransNetV2] Using weights from /mnt/ceph/develop/jiawei/lora_dataset/TransNetV2/inference/transnetv2-weights/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TransNetV2] /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1/test1.mp4.predictions.txt or /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1/test1.mp4.scenes.txt already exists. Skipping video /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1/test1.mp4.\n",
      "[TransNetV2] /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2/test2.mp4.predictions.txt or /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2/test2.mp4.scenes.txt already exists. Skipping video /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2/test2.mp4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1/test_1.mp4\n",
      "[TransNetV2] Processing video frames 5378/5378\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_10/test_10.mp4\n",
      "[TransNetV2] Processing video frames 316/316\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_11/test_11.mp4\n",
      "[TransNetV2] Processing video frames 299/299\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12/test_12.mp4\n",
      "[TransNetV2] Processing video frames 389/389\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_13/test_13.mp4\n",
      "[TransNetV2] Processing video frames 241/241\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_14/test_14.mp4\n",
      "[TransNetV2] Processing video frames 169/169\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_15/test_15.mp4\n",
      "[TransNetV2] Processing video frames 227/227\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_16/test_16.mp4\n",
      "[TransNetV2] Processing video frames 720/720\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_17/test_17.mp4\n",
      "[TransNetV2] Processing video frames 284/284\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_18/test_18.mp4\n",
      "[TransNetV2] Processing video frames 312/312\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19/test_19.mp4\n",
      "[TransNetV2] Processing video frames 195/195\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2/test_2.mp4\n",
      "[TransNetV2] Processing video frames 263/263\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_20/test_20.mp4\n",
      "[TransNetV2] Processing video frames 281/281\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21/test_21.mp4\n",
      "[TransNetV2] Processing video frames 207/207\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_22/test_22.mp4\n",
      "[TransNetV2] Processing video frames 524/524\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23/test_23.mp4\n",
      "[TransNetV2] Processing video frames 277/277\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24/test_24.mp4\n",
      "[TransNetV2] Processing video frames 268/268\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25/test_25.mp4\n",
      "[TransNetV2] Processing video frames 324/324\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26/test_26.mp4\n",
      "[TransNetV2] Processing video frames 304/304\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27/test_27.mp4\n",
      "[TransNetV2] Processing video frames 383/383\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28/test_28.mp4\n",
      "[TransNetV2] Processing video frames 279/279\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_29/test_29.mp4\n",
      "[TransNetV2] Processing video frames 227/227\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_3/test_3.mp4\n",
      "[TransNetV2] Processing video frames 315/315\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_4/test_4.mp4\n",
      "[TransNetV2] Processing video frames 278/278\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_5/test_5.mp4\n",
      "[TransNetV2] Processing video frames 236/236\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_6/test_6.mp4\n",
      "[TransNetV2] Processing video frames 580/580\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7/test_7.mp4\n",
      "[TransNetV2] Processing video frames 297/297\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8/test_8.mp4\n",
      "[TransNetV2] Processing video frames 248/248\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_9/test_9.mp4\n",
      "[TransNetV2] Processing video frames 280/280\n"
     ]
    }
   ],
   "source": [
    "from transnetv2 import TransNetV2\n",
    "visualize = False\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "load_files = []\n",
    "root_path = '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站/'\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    # 如果你只想获取下一层的子目录，可以在这里筛选\n",
    "    if root == root_path:\n",
    "        # root_dir 下的直接子目录就是 dirs 中的项\n",
    "        for dir in dirs:\n",
    "            video_path=f'{root_path}/{dir}/{dir}.mp4'\n",
    "            load_files.append(video_path)\n",
    "\n",
    "\n",
    "print(f'load_files:{load_files}')\n",
    "model = TransNetV2(None)\n",
    "\n",
    "\n",
    "\n",
    "for file in load_files:\n",
    "    if os.path.exists(file + \".predictions.txt\") or os.path.exists(file + \".scenes.txt\"):\n",
    "        print(f\"[TransNetV2] {file}.predictions.txt or {file}.scenes.txt already exists. \"\n",
    "              f\"Skipping video {file}.\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    video_frames, single_frame_predictions, all_frame_predictions = \\\n",
    "        model.predict_video(file)\n",
    "\n",
    "    predictions = np.stack([single_frame_predictions, all_frame_predictions], 1)\n",
    "    np.savetxt(file + \".predictions.txt\", predictions, fmt=\"%.6f\")\n",
    "\n",
    "    scenes = model.predictions_to_scenes(single_frame_predictions)\n",
    "    np.savetxt(file + \".scenes.txt\", scenes, fmt=\"%d\")\n",
    "\n",
    "    if visualize:\n",
    "        if os.path.exists(file + \".vis.png\"):\n",
    "            print(f\"[TransNetV2] {file}.vis.png already exists. \"\n",
    "                  f\"Skipping visualization of video {file}.\", file=sys.stderr)\n",
    "            continue\n",
    "\n",
    "        pil_image = model.visualize_predictions(\n",
    "            video_frames, predictions=(single_frame_predictions, all_frame_predictions))\n",
    "        pil_image.save(file + \".vis.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11445e-32e8-4e22-b7fe-8a5a8d92c34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
