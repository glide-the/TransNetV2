{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91d757-a040-4aa0-9105-fa74e3c6c220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting tensorflow-gpu==2.10.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6e/27/150049eed18027b8ac451e3552a036806d4afe2f49304d397d37933ef77e/tensorflow_gpu-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.66.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (3.11.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (24.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (0.37.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorflow-gpu==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.10.0) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.2.2)\n",
      "Installing collected packages: tensorflow-gpu\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.10.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af2c113-6513-44c8-9619-46a7ad27d5cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: ffmpeg-python in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: pillow in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (10.4.0)\n",
      "Requirement already satisfied: future in /mnt/ceph/develop/jiawei/conda_env/trans_net/lib/python3.10/site-packages (from ffmpeg-python) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install ffmpeg-python pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003e2341-daec-4d21-8d10-f16fced1db11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting numpy<2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/4b/d7/ecf66c1cd12dc28b4040b15ab4d17b773b87fa9d29ca16125de01adb36cd/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3773c993-bbdf-4409-9c60-6109df0baa55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- --------------\n",
      "absl-py                      2.1.0\n",
      "anyio                        4.4.0\n",
      "argon2-cffi                  23.1.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.3.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.4\n",
      "attrs                        24.2.0\n",
      "babel                        2.16.0\n",
      "beautifulsoup4               4.12.3\n",
      "bleach                       6.1.0\n",
      "cachetools                   5.5.0\n",
      "certifi                      2024.8.30\n",
      "cffi                         1.17.1\n",
      "charset-normalizer           3.3.2\n",
      "comm                         0.2.2\n",
      "debugpy                      1.8.5\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "exceptiongroup               1.2.2\n",
      "executing                    2.1.0\n",
      "fastjsonschema               2.20.0\n",
      "ffmpeg-python                0.2.0\n",
      "flatbuffers                  24.3.25\n",
      "fqdn                         1.5.1\n",
      "future                       1.0.0\n",
      "gast                         0.4.0\n",
      "google-auth                  2.34.0\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.66.1\n",
      "h11                          0.14.0\n",
      "h5py                         3.11.0\n",
      "httpcore                     1.0.5\n",
      "httpx                        0.27.2\n",
      "idna                         3.8\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.27.0\n",
      "isoduration                  20.11.0\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.4\n",
      "json5                        0.9.25\n",
      "jsonpointer                  3.0.0\n",
      "jsonschema                   4.23.0\n",
      "jsonschema-specifications    2023.12.1\n",
      "jupyter_client               8.6.2\n",
      "jupyter_core                 5.7.2\n",
      "jupyter-events               0.10.0\n",
      "jupyter-lsp                  2.2.5\n",
      "jupyter_server               2.14.2\n",
      "jupyter_server_terminals     0.5.3\n",
      "jupyterlab                   4.2.5\n",
      "jupyterlab_pygments          0.3.0\n",
      "jupyterlab_server            2.27.3\n",
      "keras                        2.10.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.7\n",
      "MarkupSafe                   2.1.5\n",
      "matplotlib-inline            0.1.7\n",
      "mistune                      3.0.2\n",
      "nbclient                     0.10.0\n",
      "nbconvert                    7.16.4\n",
      "nbformat                     5.10.4\n",
      "nest-asyncio                 1.6.0\n",
      "notebook_shim                0.2.4\n",
      "numpy                        1.26.4\n",
      "oauthlib                     3.2.2\n",
      "opt-einsum                   3.3.0\n",
      "overrides                    7.7.0\n",
      "packaging                    24.1\n",
      "pandocfilters                1.5.1\n",
      "parso                        0.8.4\n",
      "pexpect                      4.9.0\n",
      "pillow                       10.4.0\n",
      "pip                          24.2\n",
      "platformdirs                 4.2.2\n",
      "prometheus_client            0.20.0\n",
      "prompt_toolkit               3.0.47\n",
      "protobuf                     3.19.6\n",
      "psutil                       6.0.0\n",
      "ptyprocess                   0.7.0\n",
      "pure_eval                    0.2.3\n",
      "pyasn1                       0.6.0\n",
      "pyasn1_modules               0.4.0\n",
      "pycparser                    2.22\n",
      "Pygments                     2.18.0\n",
      "python-dateutil              2.9.0.post0\n",
      "python-json-logger           2.0.7\n",
      "PyYAML                       6.0.2\n",
      "pyzmq                        26.2.0\n",
      "referencing                  0.35.1\n",
      "requests                     2.32.3\n",
      "requests-oauthlib            2.0.0\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rpds-py                      0.20.0\n",
      "rsa                          4.9\n",
      "Send2Trash                   1.8.3\n",
      "setuptools                   72.1.0\n",
      "six                          1.16.0\n",
      "sniffio                      1.3.1\n",
      "soupsieve                    2.6\n",
      "stack-data                   0.6.3\n",
      "tensorboard                  2.10.1\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.10.0\n",
      "tensorflow-estimator         2.10.0\n",
      "tensorflow-io-gcs-filesystem 0.37.1\n",
      "termcolor                    2.4.0\n",
      "terminado                    0.18.1\n",
      "tinycss2                     1.3.0\n",
      "tomli                        2.0.1\n",
      "tornado                      6.4.1\n",
      "traitlets                    5.14.3\n",
      "types-python-dateutil        2.9.0.20240906\n",
      "typing_extensions            4.12.2\n",
      "uri-template                 1.3.0\n",
      "urllib3                      2.2.2\n",
      "wcwidth                      0.2.13\n",
      "webcolors                    24.8.0\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.8.0\n",
      "Werkzeug                     3.0.4\n",
      "wheel                        0.43.0\n",
      "wrapt                        1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d827efe-a75e-479c-a797-89ba5d9a2844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 18:01:30.032292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-07 18:01:30.150967: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-07 18:01:30.156358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-09-07 18:01:30.156369: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-09-07 18:01:30.181039: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-07 18:01:34.721096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-07 18:01:34.721987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-07 18:01:34.722011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74290fb3-9d2c-4a74-a973-9f6c7734b2c2",
   "metadata": {},
   "source": [
    "### ç§»åŠ¨è§†é¢‘ç¬¦åˆè¦æ±‚ç›®å½•\n",
    "æŠŠ video_orgä¸‹é¢çš„mp4æ–‡ä»¶ï¼Œç§»åŠ¨åˆ° video_org_testä¸‹é¢ ä¸€ä¸ªè§†é¢‘ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œå‘½åä½¿ç”¨test_{index}/test_{index}.mp4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b93fe76-e34b-4742-bb59-5a2f99bb7a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æžå®šï¼Œæ‰€æœ‰è§†é¢‘éƒ½æ•´å¥½äº†ï¼ðŸ’ª\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# æºæ–‡ä»¶å¤¹å’Œç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„\n",
    "source_dir = '/mnt/ceph/develop/jiawei/lora_dataset/video_org'\n",
    "dest_dir = '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™/'\n",
    "\n",
    "# èŽ·å–æ‰€æœ‰çš„ mp4 æ–‡ä»¶\n",
    "mp4_files = [f for f in os.listdir(source_dir) if f.endswith('.mp4')]\n",
    "\n",
    "# éåŽ†æ¯ä¸ªæ–‡ä»¶å¹¶åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹\n",
    "for index, file_name in enumerate(mp4_files, 1):\n",
    "    # åˆ›å»ºæ–°çš„æ–‡ä»¶å¤¹åç§°\n",
    "    new_folder_name = f'test_{index}'\n",
    "    new_folder_path = os.path.join(dest_dir, new_folder_name)\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    \n",
    "    # ç§»åŠ¨å¹¶é‡å‘½åæ–‡ä»¶\n",
    "    src_file_path = os.path.join(source_dir, file_name)\n",
    "    dest_file_path = os.path.join(new_folder_path, f'test_{index}.mp4')\n",
    "    shutil.move(src_file_path, dest_file_path)\n",
    "\n",
    "print(\"æžå®šï¼Œæ‰€æœ‰è§†é¢‘éƒ½æ•´å¥½äº†ï¼ðŸ’ª\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1f32a18-844f-4c74-948f-d90065ef1533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_files:['/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test1/test1.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test2/test2.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_1/test_1.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_10/test_10.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_11/test_11.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_12/test_12.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_13/test_13.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_14/test_14.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_15/test_15.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_16/test_16.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_17/test_17.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_18/test_18.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_19/test_19.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_2/test_2.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_20/test_20.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_21/test_21.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_22/test_22.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_23/test_23.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_24/test_24.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_25/test_25.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_26/test_26.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_27/test_27.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_28/test_28.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_29/test_29.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_3/test_3.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_4/test_4.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_5/test_5.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_6/test_6.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_7/test_7.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_8/test_8.mp4', '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_9/test_9.mp4']\n",
      "[TransNetV2] Using weights from /mnt/ceph/develop/jiawei/lora_dataset/TransNetV2/inference/transnetv2-weights/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TransNetV2] /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test1/test1.mp4.predictions.txt or /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test1/test1.mp4.scenes.txt already exists. Skipping video /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test1/test1.mp4.\n",
      "[TransNetV2] /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test2/test2.mp4.predictions.txt or /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test2/test2.mp4.scenes.txt already exists. Skipping video /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test2/test2.mp4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_1/test_1.mp4\n",
      "[TransNetV2] Processing video frames 5378/5378\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_10/test_10.mp4\n",
      "[TransNetV2] Processing video frames 316/316\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_11/test_11.mp4\n",
      "[TransNetV2] Processing video frames 299/299\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_12/test_12.mp4\n",
      "[TransNetV2] Processing video frames 389/389\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_13/test_13.mp4\n",
      "[TransNetV2] Processing video frames 241/241\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_14/test_14.mp4\n",
      "[TransNetV2] Processing video frames 169/169\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_15/test_15.mp4\n",
      "[TransNetV2] Processing video frames 227/227\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_16/test_16.mp4\n",
      "[TransNetV2] Processing video frames 720/720\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_17/test_17.mp4\n",
      "[TransNetV2] Processing video frames 284/284\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_18/test_18.mp4\n",
      "[TransNetV2] Processing video frames 312/312\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_19/test_19.mp4\n",
      "[TransNetV2] Processing video frames 195/195\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_2/test_2.mp4\n",
      "[TransNetV2] Processing video frames 263/263\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_20/test_20.mp4\n",
      "[TransNetV2] Processing video frames 281/281\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_21/test_21.mp4\n",
      "[TransNetV2] Processing video frames 207/207\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_22/test_22.mp4\n",
      "[TransNetV2] Processing video frames 524/524\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_23/test_23.mp4\n",
      "[TransNetV2] Processing video frames 277/277\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_24/test_24.mp4\n",
      "[TransNetV2] Processing video frames 268/268\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_25/test_25.mp4\n",
      "[TransNetV2] Processing video frames 324/324\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_26/test_26.mp4\n",
      "[TransNetV2] Processing video frames 304/304\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_27/test_27.mp4\n",
      "[TransNetV2] Processing video frames 383/383\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_28/test_28.mp4\n",
      "[TransNetV2] Processing video frames 279/279\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_29/test_29.mp4\n",
      "[TransNetV2] Processing video frames 227/227\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_3/test_3.mp4\n",
      "[TransNetV2] Processing video frames 315/315\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_4/test_4.mp4\n",
      "[TransNetV2] Processing video frames 278/278\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_5/test_5.mp4\n",
      "[TransNetV2] Processing video frames 236/236\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_6/test_6.mp4\n",
      "[TransNetV2] Processing video frames 580/580\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_7/test_7.mp4\n",
      "[TransNetV2] Processing video frames 297/297\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_8/test_8.mp4\n",
      "[TransNetV2] Processing video frames 248/248\n",
      "[TransNetV2] Extracting frames from /mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™//test_9/test_9.mp4\n",
      "[TransNetV2] Processing video frames 280/280\n"
     ]
    }
   ],
   "source": [
    "from transnetv2 import TransNetV2\n",
    "visualize = False\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "load_files = []\n",
    "root_path = '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/Bç«™/'\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    # å¦‚æžœä½ åªæƒ³èŽ·å–ä¸‹ä¸€å±‚çš„å­ç›®å½•ï¼Œå¯ä»¥åœ¨è¿™é‡Œç­›é€‰\n",
    "    if root == root_path:\n",
    "        # root_dir ä¸‹çš„ç›´æŽ¥å­ç›®å½•å°±æ˜¯ dirs ä¸­çš„é¡¹\n",
    "        for dir in dirs:\n",
    "            video_path=f'{root_path}/{dir}/{dir}.mp4'\n",
    "            load_files.append(video_path)\n",
    "\n",
    "\n",
    "print(f'load_files:{load_files}')\n",
    "model = TransNetV2(None)\n",
    "\n",
    "\n",
    "\n",
    "for file in load_files:\n",
    "    if os.path.exists(file + \".predictions.txt\") or os.path.exists(file + \".scenes.txt\"):\n",
    "        print(f\"[TransNetV2] {file}.predictions.txt or {file}.scenes.txt already exists. \"\n",
    "              f\"Skipping video {file}.\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    video_frames, single_frame_predictions, all_frame_predictions = \\\n",
    "        model.predict_video(file)\n",
    "\n",
    "    predictions = np.stack([single_frame_predictions, all_frame_predictions], 1)\n",
    "    np.savetxt(file + \".predictions.txt\", predictions, fmt=\"%.6f\")\n",
    "\n",
    "    scenes = model.predictions_to_scenes(single_frame_predictions)\n",
    "    np.savetxt(file + \".scenes.txt\", scenes, fmt=\"%d\")\n",
    "\n",
    "    if visualize:\n",
    "        if os.path.exists(file + \".vis.png\"):\n",
    "            print(f\"[TransNetV2] {file}.vis.png already exists. \"\n",
    "                  f\"Skipping visualization of video {file}.\", file=sys.stderr)\n",
    "            continue\n",
    "\n",
    "        pil_image = model.visualize_predictions(\n",
    "            video_frames, predictions=(single_frame_predictions, all_frame_predictions))\n",
    "        pil_image.save(file + \".vis.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11445e-32e8-4e22-b7fe-8a5a8d92c34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
